{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Context:\n",
    "Explore the relationship between screen time and mental health. Your goal is to understand\n",
    "the structure of the dataset, perform analysis, build predictive models, and interpret the\n",
    "results. You need treat the mental_health_score either as a continuous variable (regression)\n",
    "or convert it into a binary classification target:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pathlib\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#https://medium.com/@prosun.csedu/polynomialfeatures-is-a-preprocessing-tool-provided-by-the-scikit-learn-library-in-python-that-is-84118adea049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Abdelouaheb\\perso\\Data_science_2024_projects\\2025\\machine_learning_project_Ames_House_Price\\test_solution\n",
      "c:\\Abdelouaheb\\perso\\Data_science_2024_projects\\2025\\machine_learning_project_Ames_House_Price\\test_solution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>daily_screen_time_hours</th>\n",
       "      <th>phone_usage_hours</th>\n",
       "      <th>laptop_usage_hours</th>\n",
       "      <th>tablet_usage_hours</th>\n",
       "      <th>tv_usage_hours</th>\n",
       "      <th>social_media_hours</th>\n",
       "      <th>work_related_hours</th>\n",
       "      <th>...</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>physical_activity_hours_per_week</th>\n",
       "      <th>location_type</th>\n",
       "      <th>mental_health_score</th>\n",
       "      <th>uses_wellness_apps</th>\n",
       "      <th>eats_healthy</th>\n",
       "      <th>caffeine_intake_mg_per_day</th>\n",
       "      <th>weekly_anxiety_score</th>\n",
       "      <th>weekly_depression_score</th>\n",
       "      <th>mindfulness_minutes_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Urban</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>64</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.4</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>41</td>\n",
       "      <td>Other</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187.9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_4</td>\n",
       "      <td>27</td>\n",
       "      <td>Other</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_5</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>217.5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  age  gender  daily_screen_time_hours  phone_usage_hours  \\\n",
       "0  user_1   51  Female                      4.8                3.4   \n",
       "1  user_2   64    Male                      3.9                3.5   \n",
       "2  user_3   41   Other                     10.5                2.1   \n",
       "3  user_4   27   Other                      8.8                0.0   \n",
       "4  user_5   55    Male                      5.9                1.7   \n",
       "\n",
       "   laptop_usage_hours  tablet_usage_hours  tv_usage_hours  social_media_hours  \\\n",
       "0                 1.3                 1.6             1.6                 4.1   \n",
       "1                 1.8                 0.9             2.0                 2.7   \n",
       "2                 2.6                 0.7             2.2                 3.0   \n",
       "3                 0.0                 0.7             2.5                 3.3   \n",
       "4                 1.1                 1.5             1.6                 1.1   \n",
       "\n",
       "   work_related_hours  ...  stress_level  physical_activity_hours_per_week  \\\n",
       "0                 2.0  ...            10                               0.7   \n",
       "1                 3.1  ...             6                               4.3   \n",
       "2                 2.8  ...             5                               3.1   \n",
       "3                 1.6  ...             5                               0.0   \n",
       "4                 3.6  ...             7                               3.0   \n",
       "\n",
       "   location_type  mental_health_score  uses_wellness_apps  eats_healthy  \\\n",
       "0          Urban                   32                   1             1   \n",
       "1       Suburban                   75                   0             1   \n",
       "2       Suburban                   22                   0             0   \n",
       "3          Rural                   22                   0             1   \n",
       "4          Urban                   64                   1             1   \n",
       "\n",
       "   caffeine_intake_mg_per_day weekly_anxiety_score  weekly_depression_score  \\\n",
       "0                       125.2                   13                       15   \n",
       "1                       150.4                   19                       18   \n",
       "2                       187.9                    7                        3   \n",
       "3                        73.6                    7                        2   \n",
       "4                       217.5                    8                       10   \n",
       "\n",
       "   mindfulness_minutes_per_day  \n",
       "0                          4.0  \n",
       "1                          6.5  \n",
       "2                          6.9  \n",
       "3                          4.8  \n",
       "4                          0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(file_name : str )  -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dir_folder = pathlib.Path().cwd()\n",
    "        print(dir_folder)\n",
    "        file_path  = dir_folder\n",
    "        print(file_path)\n",
    "        df = pd.read_csv(os.path.join(file_path/file_name))\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at '{file_name}' was not found.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "         print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "df = read_file('digital_diet_mental_health.csv')      \n",
    "  \n",
    "df.head()   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_diagnostic(df):\n",
    "        print(\"#\"*50)\n",
    "        print(df.info())\n",
    "        print(\"#\"*50)\n",
    "        print(\"The number of total rows  {x: .0f} \".format(x=df.shape[0]))\n",
    "        print(\"The number of total variables {x: .0f} \".format(x=df.shape[1]))\n",
    "        print(\"The variables names {x:} \".format(x=list(df.columns.values)))\n",
    "\n",
    "        column_headers =list(df.columns.values)\n",
    "        qualitative_columns = [col for col in column_headers if df[col].dtype==\"object\"]\n",
    "        quantitative_columns = [col for col in column_headers if df[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "        print(\"The qualitative variables {x:} \".format(x=qualitative_columns))\n",
    "        print(\"The quantitative variables {x:} \".format(x=quantitative_columns))\n",
    "        print(\"#\"*50)\n",
    "        print(\"Total number missing value {x:} \".format(x=df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>daily_screen_time_hours</th>\n",
       "      <th>phone_usage_hours</th>\n",
       "      <th>laptop_usage_hours</th>\n",
       "      <th>tablet_usage_hours</th>\n",
       "      <th>tv_usage_hours</th>\n",
       "      <th>social_media_hours</th>\n",
       "      <th>work_related_hours</th>\n",
       "      <th>...</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>physical_activity_hours_per_week</th>\n",
       "      <th>location_type</th>\n",
       "      <th>mental_health_score</th>\n",
       "      <th>uses_wellness_apps</th>\n",
       "      <th>eats_healthy</th>\n",
       "      <th>caffeine_intake_mg_per_day</th>\n",
       "      <th>weekly_anxiety_score</th>\n",
       "      <th>weekly_depression_score</th>\n",
       "      <th>mindfulness_minutes_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Urban</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>64</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.4</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>41</td>\n",
       "      <td>Other</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187.9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_4</td>\n",
       "      <td>27</td>\n",
       "      <td>Other</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_5</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>217.5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>user_1996</td>\n",
       "      <td>58</td>\n",
       "      <td>Female</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164.9</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>user_1997</td>\n",
       "      <td>62</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Urban</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172.6</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>user_1998</td>\n",
       "      <td>64</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Urban</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>user_1999</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Urban</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123.7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>user_2000</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Urban</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>173.1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  age  gender  daily_screen_time_hours  phone_usage_hours  \\\n",
       "0        user_1   51  Female                      4.8                3.4   \n",
       "1        user_2   64    Male                      3.9                3.5   \n",
       "2        user_3   41   Other                     10.5                2.1   \n",
       "3        user_4   27   Other                      8.8                0.0   \n",
       "4        user_5   55    Male                      5.9                1.7   \n",
       "...         ...  ...     ...                      ...                ...   \n",
       "1995  user_1996   58  Female                      5.6                4.0   \n",
       "1996  user_1997   62  Female                      3.9                3.1   \n",
       "1997  user_1998   64  Female                      7.4                3.0   \n",
       "1998  user_1999   19    Male                      4.2                4.4   \n",
       "1999  user_2000   15  Female                      4.5                3.6   \n",
       "\n",
       "      laptop_usage_hours  tablet_usage_hours  tv_usage_hours  \\\n",
       "0                    1.3                 1.6             1.6   \n",
       "1                    1.8                 0.9             2.0   \n",
       "2                    2.6                 0.7             2.2   \n",
       "3                    0.0                 0.7             2.5   \n",
       "4                    1.1                 1.5             1.6   \n",
       "...                  ...                 ...             ...   \n",
       "1995                 2.5                 0.3             1.5   \n",
       "1996                 1.0                 1.5             1.1   \n",
       "1997                 0.0                 1.4             0.9   \n",
       "1998                 2.3                 0.9             1.4   \n",
       "1999                 1.2                 1.4             1.8   \n",
       "\n",
       "      social_media_hours  work_related_hours  ...  stress_level  \\\n",
       "0                    4.1                 2.0  ...            10   \n",
       "1                    2.7                 3.1  ...             6   \n",
       "2                    3.0                 2.8  ...             5   \n",
       "3                    3.3                 1.6  ...             5   \n",
       "4                    1.1                 3.6  ...             7   \n",
       "...                  ...                 ...  ...           ...   \n",
       "1995                 1.1                 1.2  ...             9   \n",
       "1996                 2.7                 4.1  ...             8   \n",
       "1997                 0.8                 2.6  ...             4   \n",
       "1998                 1.7                 1.2  ...             8   \n",
       "1999                 2.7                 1.8  ...            10   \n",
       "\n",
       "      physical_activity_hours_per_week  location_type  mental_health_score  \\\n",
       "0                                  0.7          Urban                   32   \n",
       "1                                  4.3       Suburban                   75   \n",
       "2                                  3.1       Suburban                   22   \n",
       "3                                  0.0          Rural                   22   \n",
       "4                                  3.0          Urban                   64   \n",
       "...                                ...            ...                  ...   \n",
       "1995                               0.0          Urban                   62   \n",
       "1996                               2.7          Urban                   29   \n",
       "1997                               6.5          Urban                   54   \n",
       "1998                               2.6          Urban                   28   \n",
       "1999                               6.3          Urban                   59   \n",
       "\n",
       "      uses_wellness_apps  eats_healthy  caffeine_intake_mg_per_day  \\\n",
       "0                      1             1                       125.2   \n",
       "1                      0             1                       150.4   \n",
       "2                      0             0                       187.9   \n",
       "3                      0             1                        73.6   \n",
       "4                      1             1                       217.5   \n",
       "...                  ...           ...                         ...   \n",
       "1995                   0             1                       164.9   \n",
       "1996                   0             0                       172.6   \n",
       "1997                   1             0                       101.3   \n",
       "1998                   0             0                       123.7   \n",
       "1999                   1             0                       173.1   \n",
       "\n",
       "     weekly_anxiety_score  weekly_depression_score  \\\n",
       "0                      13                       15   \n",
       "1                      19                       18   \n",
       "2                       7                        3   \n",
       "3                       7                        2   \n",
       "4                       8                       10   \n",
       "...                   ...                      ...   \n",
       "1995                   20                       17   \n",
       "1996                   15                       15   \n",
       "1997                    1                       20   \n",
       "1998                    1                       11   \n",
       "1999                    0                       17   \n",
       "\n",
       "      mindfulness_minutes_per_day  \n",
       "0                             4.0  \n",
       "1                             6.5  \n",
       "2                             6.9  \n",
       "3                             4.8  \n",
       "4                             0.0  \n",
       "...                           ...  \n",
       "1995                          4.9  \n",
       "1996                         25.5  \n",
       "1997                          9.5  \n",
       "1998                         13.4  \n",
       "1999                         10.0  \n",
       "\n",
       "[2000 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   user_id                           2000 non-null   object \n",
      " 1   age                               2000 non-null   int64  \n",
      " 2   gender                            2000 non-null   object \n",
      " 3   daily_screen_time_hours           2000 non-null   float64\n",
      " 4   phone_usage_hours                 2000 non-null   float64\n",
      " 5   laptop_usage_hours                2000 non-null   float64\n",
      " 6   tablet_usage_hours                2000 non-null   float64\n",
      " 7   tv_usage_hours                    2000 non-null   float64\n",
      " 8   social_media_hours                2000 non-null   float64\n",
      " 9   work_related_hours                2000 non-null   float64\n",
      " 10  entertainment_hours               2000 non-null   float64\n",
      " 11  gaming_hours                      2000 non-null   float64\n",
      " 12  sleep_duration_hours              2000 non-null   float64\n",
      " 13  sleep_quality                     2000 non-null   int64  \n",
      " 14  mood_rating                       2000 non-null   int64  \n",
      " 15  stress_level                      2000 non-null   int64  \n",
      " 16  physical_activity_hours_per_week  2000 non-null   float64\n",
      " 17  location_type                     2000 non-null   object \n",
      " 18  mental_health_score               2000 non-null   int64  \n",
      " 19  uses_wellness_apps                2000 non-null   int64  \n",
      " 20  eats_healthy                      2000 non-null   int64  \n",
      " 21  caffeine_intake_mg_per_day        2000 non-null   float64\n",
      " 22  weekly_anxiety_score              2000 non-null   int64  \n",
      " 23  weekly_depression_score           2000 non-null   int64  \n",
      " 24  mindfulness_minutes_per_day       2000 non-null   float64\n",
      "dtypes: float64(13), int64(9), object(3)\n",
      "memory usage: 390.8+ KB\n",
      "None\n",
      "##################################################\n",
      "The number of total rows   2000 \n",
      "The number of total variables  25 \n",
      "The variables names ['user_id', 'age', 'gender', 'daily_screen_time_hours', 'phone_usage_hours', 'laptop_usage_hours', 'tablet_usage_hours', 'tv_usage_hours', 'social_media_hours', 'work_related_hours', 'entertainment_hours', 'gaming_hours', 'sleep_duration_hours', 'sleep_quality', 'mood_rating', 'stress_level', 'physical_activity_hours_per_week', 'location_type', 'mental_health_score', 'uses_wellness_apps', 'eats_healthy', 'caffeine_intake_mg_per_day', 'weekly_anxiety_score', 'weekly_depression_score', 'mindfulness_minutes_per_day'] \n",
      "The qualitative variables ['user_id', 'gender', 'location_type'] \n",
      "The quantitative variables ['age', 'daily_screen_time_hours', 'phone_usage_hours', 'laptop_usage_hours', 'tablet_usage_hours', 'tv_usage_hours', 'social_media_hours', 'work_related_hours', 'entertainment_hours', 'gaming_hours', 'sleep_duration_hours', 'sleep_quality', 'mood_rating', 'stress_level', 'physical_activity_hours_per_week', 'mental_health_score', 'uses_wellness_apps', 'eats_healthy', 'caffeine_intake_mg_per_day', 'weekly_anxiety_score', 'weekly_depression_score', 'mindfulness_minutes_per_day'] \n",
      "##################################################\n",
      "Total number missing value user_id                             0\n",
      "age                                 0\n",
      "gender                              0\n",
      "daily_screen_time_hours             0\n",
      "phone_usage_hours                   0\n",
      "laptop_usage_hours                  0\n",
      "tablet_usage_hours                  0\n",
      "tv_usage_hours                      0\n",
      "social_media_hours                  0\n",
      "work_related_hours                  0\n",
      "entertainment_hours                 0\n",
      "gaming_hours                        0\n",
      "sleep_duration_hours                0\n",
      "sleep_quality                       0\n",
      "mood_rating                         0\n",
      "stress_level                        0\n",
      "physical_activity_hours_per_week    0\n",
      "location_type                       0\n",
      "mental_health_score                 0\n",
      "uses_wellness_apps                  0\n",
      "eats_healthy                        0\n",
      "caffeine_intake_mg_per_day          0\n",
      "weekly_anxiety_score                0\n",
      "weekly_depression_score             0\n",
      "mindfulness_minutes_per_day         0\n",
      "dtype: int64 \n"
     ]
    }
   ],
   "source": [
    "data_diagnostic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NaNs in df:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def na(df, percent = True, verbose = True):\n",
    "    srs = df.isna().sum()[df.isna().sum() > 0]\n",
    "    srs = srs.sort_values(ascending=False)\n",
    "    if percent:\n",
    "       if verbose:\n",
    "           print('% of NaNs in df:')\n",
    "       return srs / df.shape[0]\n",
    "    else:\n",
    "        if verbose:\n",
    "           print('# of NaNs in df:')\n",
    "        return srs\n",
    "\n",
    "na(df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse univary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical varaiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df dtypes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype\n",
       "int64       9\n",
       "float64    13\n",
       "object      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes = df.dtypes.to_frame().reset_index()\n",
    "dtypes.columns = ['col', 'dtype']\n",
    "print('Df dtypes:')\n",
    "dtypes.groupby('dtype').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_analysis(df):\n",
    "        \n",
    "    \n",
    "        return print(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   count       mean        std   min    25%  \\\n",
      "age                               2000.0   38.80550  14.929203  13.0   26.0   \n",
      "daily_screen_time_hours           2000.0    6.02560   1.974123   0.0    4.7   \n",
      "phone_usage_hours                 2000.0    3.02370   1.449399   0.0    2.0   \n",
      "laptop_usage_hours                2000.0    1.99995   0.997949   0.0    1.3   \n",
      "tablet_usage_hours                2000.0    0.99565   0.492714   0.0    0.6   \n",
      "tv_usage_hours                    2000.0    1.50370   0.959003   0.0    0.8   \n",
      "social_media_hours                2000.0    2.03920   1.133435   0.0    1.2   \n",
      "work_related_hours                2000.0    2.01025   1.116111   0.0    1.2   \n",
      "entertainment_hours               2000.0    2.46735   1.236860   0.0    1.6   \n",
      "gaming_hours                      2000.0    1.27950   0.894500   0.0    0.6   \n",
      "sleep_duration_hours              2000.0    6.53755   1.203856   3.0    5.7   \n",
      "sleep_quality                     2000.0    5.56700   2.826217   1.0    3.0   \n",
      "mood_rating                       2000.0    5.59100   2.899814   1.0    3.0   \n",
      "stress_level                      2000.0    5.54150   2.885731   1.0    3.0   \n",
      "physical_activity_hours_per_week  2000.0    3.08715   1.885258   0.0    1.6   \n",
      "mental_health_score               2000.0   49.65050  17.546717  20.0   35.0   \n",
      "uses_wellness_apps                2000.0    0.38750   0.487301   0.0    0.0   \n",
      "eats_healthy                      2000.0    0.50750   0.500069   0.0    0.0   \n",
      "caffeine_intake_mg_per_day        2000.0  148.07970  48.860660   0.8  113.9   \n",
      "weekly_anxiety_score              2000.0    9.88750   6.027853   0.0    5.0   \n",
      "weekly_depression_score           2000.0   10.04900   6.053340   0.0    5.0   \n",
      "mindfulness_minutes_per_day       2000.0   10.75375   7.340269   0.0    4.9   \n",
      "\n",
      "                                     50%      75%    max  \n",
      "age                                39.00   51.000   64.0  \n",
      "daily_screen_time_hours             6.00    7.325   13.3  \n",
      "phone_usage_hours                   3.00    4.000    8.4  \n",
      "laptop_usage_hours                  2.00    2.700    5.6  \n",
      "tablet_usage_hours                  1.00    1.300    2.5  \n",
      "tv_usage_hours                      1.50    2.200    4.7  \n",
      "social_media_hours                  2.00    2.800    5.8  \n",
      "work_related_hours                  2.00    2.800    5.9  \n",
      "entertainment_hours                 2.40    3.300    6.8  \n",
      "gaming_hours                        1.20    1.900    4.0  \n",
      "sleep_duration_hours                6.60    7.400   10.0  \n",
      "sleep_quality                       6.00    8.000   10.0  \n",
      "mood_rating                         6.00    8.000   10.0  \n",
      "stress_level                        6.00    8.000   10.0  \n",
      "physical_activity_hours_per_week    3.00    4.400    9.7  \n",
      "mental_health_score                49.00   64.250   80.0  \n",
      "uses_wellness_apps                  0.00    1.000    1.0  \n",
      "eats_healthy                        1.00    1.000    1.0  \n",
      "caffeine_intake_mg_per_day        147.45  180.700  364.9  \n",
      "weekly_anxiety_score               10.00   15.000   20.0  \n",
      "weekly_depression_score            10.00   15.000   20.0  \n",
      "mindfulness_minutes_per_day        10.40   15.800   36.4  \n"
     ]
    }
   ],
   "source": [
    "numeric_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical varaiables visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_analysis(df, base_folder=\"univariate_analysis\"):\n",
    "        # Ensure the base folder exists\n",
    "        if not os.path.exists(base_folder):\n",
    "            os.makedirs(base_folder)\n",
    "        \n",
    "        # Select numeric columns\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            # Create a folder for the analysis\n",
    "            col_folder = os.path.join(base_folder, col)\n",
    "            if not os.path.exists(col_folder):\n",
    "                os.makedirs(col_folder)\n",
    "            \n",
    "            print(f\"\\nPerforming Univariate Analysis for: {col}\")\n",
    "            \n",
    "            # Create a single figure with 2x2 layout\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "            fig.suptitle(f'Univariate Analysis for {col}', fontsize=16)\n",
    "            \n",
    "            # Bar Chart\n",
    "            sns.barplot(\n",
    "                x=df[col].value_counts().index, \n",
    "                y=df[col].value_counts().values, \n",
    "                palette=\"viridis\", \n",
    "                ax=axes[0, 0]\n",
    "            )\n",
    "            axes[0, 0].set_title('Bar Chart')\n",
    "            axes[0, 0].set_xlabel(col)\n",
    "            axes[0, 0].set_ylabel('Frequency')\n",
    "            \n",
    "            # Box Plot\n",
    "            sns.boxplot(y=df[col], palette=\"viridis\", ax=axes[0, 1])\n",
    "            axes[0, 1].set_title('Box Plot')\n",
    "            axes[0, 1].set_xlabel(col)\n",
    "            \n",
    "            # Density Plot\n",
    "            sns.kdeplot(df[col], fill=True, color=\"blue\", alpha=0.6, ax=axes[1, 0])\n",
    "            axes[1, 0].set_title('Density Plot')\n",
    "            axes[1, 0].set_xlabel(col)\n",
    "            axes[1, 0].set_ylabel('Density')\n",
    "            \n",
    "            # Histogram\n",
    "            sns.histplot(df[col], kde=False, color=\"green\", ax=axes[1, 1])\n",
    "            axes[1, 1].set_title('Histogram')\n",
    "            axes[1, 1].set_xlabel(col)\n",
    "            axes[1, 1].set_ylabel('Frequency')\n",
    "            \n",
    "            # Adjust layout\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.96])  # Make room for the main title\n",
    "            \n",
    "            # Save the combined plot\n",
    "            combined_plot_path = os.path.join(col_folder, f\"{col}_univariate_analysis.png\")\n",
    "            plt.savefig(combined_plot_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Combined plots for {col} saved in: {combined_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis(df, base_folder=\"univariate_analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical varaiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_analysis(df):\n",
    "    return print(df.select_dtypes(include='object').describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              count unique     top freq\n",
      "user_id        2000   2000  user_1    1\n",
      "gender         2000      3  Female  935\n",
      "location_type  2000      3   Urban  999\n"
     ]
    }
   ],
   "source": [
    "categorical_analysis(df)\n",
    "# Percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical varaiables visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_analysis_categorical(df, base_folder=\"univariate_analysis_categorical\"):\n",
    "    # Ensure the base folder exists\n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "    \n",
    "    # Select categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        # Create a folder for the analysis\n",
    "        col_folder = os.path.join(base_folder, col)\n",
    "        if not os.path.exists(col_folder):\n",
    "            os.makedirs(col_folder)\n",
    "        \n",
    "        print(f\"\\nPerforming Univariate Analysis for: {col}\")\n",
    "        \n",
    "        # Create a figure with 1x2 layout\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        fig.suptitle(f'Univariate Analysis for {col}', fontsize=16)\n",
    "        \n",
    "        # Bar Plot\n",
    "        sns.countplot(x=df[col], palette=\"viridis\", ax=axes[0])\n",
    "        axes[0].set_title('Count Plot')\n",
    "        axes[0].set_xlabel(col)\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Pie Chart\n",
    "        df[col].value_counts().plot.pie(\n",
    "            autopct='%1.1f%%', \n",
    "            colors=sns.color_palette(\"viridis\", len(df[col].unique())), \n",
    "            ax=axes[1], \n",
    "            startangle=90\n",
    "        )\n",
    "        axes[1].set_title('Pie Chart')\n",
    "        axes[1].set_ylabel('')  # Remove y-label for better visualization\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])  # Make room for the main title\n",
    "        \n",
    "        # Save the combined plot\n",
    "        combined_plot_path = os.path.join(col_folder, f\"{col}_univariate_analysis.png\")\n",
    "        plt.savefig(combined_plot_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Combined plots for {col} saved in: {combined_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis_categorical(df, base_folder=\"univariate_analysis_categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def correlation_and_significance(df, base_folder=\"correlation_analysis\"):\n",
    "    \"\"\"\n",
    "    Generates a correlation matrix heatmap with significance markers.\n",
    "    Outputs:\n",
    "        - Correlation Matrix with significance points (red = not significant, green = significant)\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to analyze.\n",
    "        base_folder (str): Directory to save the analysis images.\n",
    "    \"\"\"\n",
    "    # Ensure the base folder exists\n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "    \n",
    "    # Select only numerical columns\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    cols = numeric_df.columns\n",
    "    \n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    \n",
    "    # Initialize p-value matrix\n",
    "    p_values = pd.DataFrame(np.ones((len(cols), len(cols))), columns=cols, index=cols)\n",
    "    \n",
    "    # Calculate p-values for each pair of variables\n",
    "    for row in cols:\n",
    "        for col in cols:\n",
    "            if row != col:\n",
    "                _, p_value = pearsonr(numeric_df[row], numeric_df[col])\n",
    "                p_values.loc[row, col] = p_value\n",
    "    \n",
    "    # --- Plot Correlation Matrix with Significance ---\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    \n",
    "    # Add significance markers\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(len(cols)):\n",
    "            if i != j:  # Skip diagonal\n",
    "                p_val = p_values.iloc[i, j]\n",
    "                x = j + 0.5\n",
    "                y = i + 0.5\n",
    "                \n",
    "                # Significant if p-value < 0.05\n",
    "                if p_val < 0.05:\n",
    "                    plt.plot(x, y, 'o', color='green')  # Green for significant\n",
    "                else:\n",
    "                    plt.plot(x, y, 'o', color='red')    # Red for not significant\n",
    "    \n",
    "    plt.title('Correlation Matrix with Significance (Numerical Variables)', fontsize=18)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save Correlation Matrix with Significance\n",
    "    corr_plot_path = os.path.join(base_folder, \"correlation_matrix_significance.png\")\n",
    "    plt.savefig(corr_plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Correlation matrix with significance saved in: {corr_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix with significance saved in: correlation_analysis\\correlation_matrix_significance.png\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "correlation_and_significance(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def impute_dataframe(df, strategy_num=\"mean\", strategy_cat=\"most_frequent\"):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a DataFrame separately for numerical and categorical columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame.\n",
    "    strategy_num (str): Strategy for imputing numerical columns (default=\"mean\").\n",
    "    strategy_cat (str): Strategy for imputing categorical columns (default=\"most_frequent\").\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with imputed values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Separate numerical and categorical columns\n",
    "    num_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "    cat_cols = df.select_dtypes(exclude=[\"number\"]).columns\n",
    "\n",
    "    # Impute numerical columns\n",
    "    if len(num_cols) > 0:\n",
    "        num_imputer = SimpleImputer(strategy=strategy_num)\n",
    "        df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "\n",
    "    # Impute categorical columns\n",
    "    if len(cat_cols) > 0:\n",
    "        cat_imputer = SimpleImputer(strategy=strategy_cat)\n",
    "        df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing duplicates rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df, subset=None, keep='first', inplace=False):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows from the DataFrame and provides a summary of duplicates.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame from which to remove duplicates.\n",
    "        subset (list): List of columns to consider for duplicate checking. \n",
    "                       If None, checks all columns.\n",
    "        keep (str): Which duplicates to keep. Options:\n",
    "            - 'first': Keep the first occurrence (default).\n",
    "            - 'last': Keep the last occurrence.\n",
    "            - 'none': Drop all duplicates.\n",
    "        inplace (bool): If True, modifies the original DataFrame. \n",
    "                        If False, returns a new DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed (if inplace=False).\n",
    "    \"\"\"\n",
    "    if keep not in ['first', 'last', 'none']:\n",
    "        raise ValueError(\"keep must be one of 'first', 'last', or 'none'.\")\n",
    "    \n",
    "    # Count duplicates before removal\n",
    "    total_rows = len(df)\n",
    "    duplicate_rows = df.duplicated(subset=subset, keep=False).sum()\n",
    "    percentage_duplicates = (duplicate_rows / total_rows) * 100\n",
    "    \n",
    "    print(f\"Total Rows: {total_rows}\")\n",
    "    print(f\"Duplicate Rows: {duplicate_rows} ({percentage_duplicates:.2f}%)\")\n",
    "    \n",
    "    if duplicate_rows == 0:\n",
    "        print(\"No duplicates found. No rows removed.\")\n",
    "        return df if not inplace else None\n",
    "    \n",
    "    # Handle duplicate removal\n",
    "    if keep == 'none':\n",
    "        # Drop all duplicates and keep only unique rows\n",
    "        duplicated_mask = df.duplicated(subset=subset, keep=False)\n",
    "        result = df[~duplicated_mask]\n",
    "    else:\n",
    "        # Use pandas built-in drop_duplicates\n",
    "        result = df.drop_duplicates(subset=subset, keep=keep)\n",
    "    \n",
    "    # Count duplicates after removal\n",
    "    remaining_rows = len(result)\n",
    "    rows_removed = total_rows - remaining_rows\n",
    "    \n",
    "    print(f\"Rows Removed: {rows_removed}\")\n",
    "    print(f\"Remaining Rows: {remaining_rows}\")\n",
    "    \n",
    "    if rows_removed > 0:\n",
    "        print(\"Duplicates successfully removed.\")\n",
    "    else:\n",
    "        print(\"No duplicates were removed.\")\n",
    "    \n",
    "    if inplace:\n",
    "        df.drop_duplicates(subset=subset, keep=keep, inplace=True)\n",
    "    else:\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 2000\n",
      "Duplicate Rows: 0 (0.00%)\n",
      "No duplicates found. No rows removed.\n"
     ]
    }
   ],
   "source": [
    "dm=remove_duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handles outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, numerical_columns=None, method='IQR', verbose=True):\n",
    "    \"\"\"\n",
    "    Handles outliers in continuous numerical variables using the specified method.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        numerical_columns (list): List of numerical columns to check for outliers. If None, auto-selects all numerical columns.\n",
    "        method (str): Method to handle outliers ('IQR' or 'Z-Score'). Default is 'IQR'.\n",
    "        verbose (bool): If True, displays outlier statistics.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with outliers handled.\n",
    "    \"\"\"\n",
    "    # Select numerical columns if not provided\n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    # Iterate over each numerical column\n",
    "    for col in numerical_columns:\n",
    "        if col in df.columns:\n",
    "            if method == 'IQR':\n",
    "                # Calculate Q1, Q3, and IQR\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                \n",
    "                # Count and handle outliers\n",
    "                outliers = ((df[col] < lower_bound) | (df[col] > upper_bound))\n",
    "                num_outliers = outliers.sum()\n",
    "                \n",
    "                # Option 1: Capping\n",
    "                df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "                df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"[INFO] Outliers handled in '{col}' using IQR:\")\n",
    "                    print(f\"         - Number of Outliers: {num_outliers}\")\n",
    "                    print(f\"         - Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
    "            \n",
    "            elif method == 'Z-Score':\n",
    "                # Alternative method (if needed)\n",
    "                mean = df[col].mean()\n",
    "                std_dev = df[col].std()\n",
    "                threshold = 3  # Standard deviation threshold\n",
    "                \n",
    "                # Count and handle outliers\n",
    "                outliers = ((df[col] < (mean - threshold * std_dev)) | (df[col] > (mean + threshold * std_dev)))\n",
    "                num_outliers = outliers.sum()\n",
    "                \n",
    "                # Option 1: Capping\n",
    "                lower_bound = mean - threshold * std_dev\n",
    "                upper_bound = mean + threshold * std_dev\n",
    "                df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "                df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"[INFO] Outliers handled in '{col}' using Z-Score:\")\n",
    "                    print(f\"         - Number of Outliers: {num_outliers}\")\n",
    "                    print(f\"         - Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc=handle_outliers(dm, numerical_columns=None, method='IQR', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data type conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   user_id                           2000 non-null   object \n",
      " 1   age                               2000 non-null   float64\n",
      " 2   gender                            2000 non-null   object \n",
      " 3   daily_screen_time_hours           2000 non-null   float64\n",
      " 4   phone_usage_hours                 2000 non-null   float64\n",
      " 5   laptop_usage_hours                2000 non-null   float64\n",
      " 6   tablet_usage_hours                2000 non-null   float64\n",
      " 7   tv_usage_hours                    2000 non-null   float64\n",
      " 8   social_media_hours                2000 non-null   float64\n",
      " 9   work_related_hours                2000 non-null   float64\n",
      " 10  entertainment_hours               2000 non-null   float64\n",
      " 11  gaming_hours                      2000 non-null   float64\n",
      " 12  sleep_duration_hours              2000 non-null   float64\n",
      " 13  sleep_quality                     2000 non-null   float64\n",
      " 14  mood_rating                       2000 non-null   float64\n",
      " 15  stress_level                      2000 non-null   float64\n",
      " 16  physical_activity_hours_per_week  2000 non-null   float64\n",
      " 17  location_type                     2000 non-null   object \n",
      " 18  mental_health_score               2000 non-null   float64\n",
      " 19  uses_wellness_apps                2000 non-null   float64\n",
      " 20  eats_healthy                      2000 non-null   float64\n",
      " 21  caffeine_intake_mg_per_day        2000 non-null   float64\n",
      " 22  weekly_anxiety_score              2000 non-null   int64  \n",
      " 23  weekly_depression_score           2000 non-null   int64  \n",
      " 24  mindfulness_minutes_per_day       2000 non-null   float64\n",
      "dtypes: float64(20), int64(2), object(3)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'location_type']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_object_columns(df):\n",
    "    \"\"\"\n",
    "    Cette fonction retourne la liste des colonnes de type 'object' dans un DataFrame.\n",
    "    \n",
    "    ParamÃ¨tres :\n",
    "    df (pd.DataFrame) : Le DataFrame Ã  analyser.\n",
    "    \n",
    "    Retour :\n",
    "    list : Liste des noms de colonnes de type 'object'.\n",
    "    \"\"\"\n",
    "    return df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# df = pd.read_csv('ton_fichier.csv')\n",
    "object_columns = get_object_columns(dc)\n",
    "print(object_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = dc.drop('user_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_columns(df, columns=object_columns, verbose=True):\n",
    "    \"\"\"\n",
    "    Performs Label Encoding on specified categorical columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to encode.\n",
    "        columns (list): List of column names to be label encoded.\n",
    "        verbose (bool): If True, displays the label mappings.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with encoded columns.\n",
    "    \"\"\"\n",
    "    # Loop through the specified columns and encode them\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            \n",
    "            # Display label mapping\n",
    "            if verbose:\n",
    "                mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(f\"\\n[INFO] Label Encoding for '{col}': {mapping}\")\n",
    "        else:\n",
    "            print(f\"[WARNING] Column '{col}' not found in DataFrame.\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Label Encoding for 'gender': {'Female': 0, 'Male': 1, 'Other': 2}\n",
      "\n",
      "[INFO] Label Encoding for 'location_type': {'Rural': 0, 'Suburban': 1, 'Urban': 2}\n"
     ]
    }
   ],
   "source": [
    "dc=label_encode_columns(dc, columns=object_columns, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>daily_screen_time_hours</th>\n",
       "      <th>phone_usage_hours</th>\n",
       "      <th>laptop_usage_hours</th>\n",
       "      <th>tablet_usage_hours</th>\n",
       "      <th>tv_usage_hours</th>\n",
       "      <th>social_media_hours</th>\n",
       "      <th>work_related_hours</th>\n",
       "      <th>entertainment_hours</th>\n",
       "      <th>...</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>physical_activity_hours_per_week</th>\n",
       "      <th>location_type</th>\n",
       "      <th>mental_health_score</th>\n",
       "      <th>uses_wellness_apps</th>\n",
       "      <th>eats_healthy</th>\n",
       "      <th>caffeine_intake_mg_per_day</th>\n",
       "      <th>weekly_anxiety_score</th>\n",
       "      <th>weekly_depression_score</th>\n",
       "      <th>mindfulness_minutes_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.4</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.10</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.6</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender  daily_screen_time_hours  phone_usage_hours  \\\n",
       "0     51.0       0                      4.8                3.4   \n",
       "1     64.0       1                      3.9                3.5   \n",
       "2     41.0       2                     10.5                2.1   \n",
       "3     27.0       2                      8.8                0.0   \n",
       "4     55.0       1                      5.9                1.7   \n",
       "...    ...     ...                      ...                ...   \n",
       "1995  58.0       0                      5.6                4.0   \n",
       "1996  62.0       0                      3.9                3.1   \n",
       "1997  64.0       0                      7.4                3.0   \n",
       "1998  19.0       1                      4.2                4.4   \n",
       "1999  15.0       0                      4.5                3.6   \n",
       "\n",
       "      laptop_usage_hours  tablet_usage_hours  tv_usage_hours  \\\n",
       "0                    1.3                 1.6             1.6   \n",
       "1                    1.8                 0.9             2.0   \n",
       "2                    2.6                 0.7             2.2   \n",
       "3                    0.0                 0.7             2.5   \n",
       "4                    1.1                 1.5             1.6   \n",
       "...                  ...                 ...             ...   \n",
       "1995                 2.5                 0.3             1.5   \n",
       "1996                 1.0                 1.5             1.1   \n",
       "1997                 0.0                 1.4             0.9   \n",
       "1998                 2.3                 0.9             1.4   \n",
       "1999                 1.2                 1.4             1.8   \n",
       "\n",
       "      social_media_hours  work_related_hours  entertainment_hours  ...  \\\n",
       "0                    4.1                 2.0                 1.00  ...   \n",
       "1                    2.7                 3.1                 1.00  ...   \n",
       "2                    3.0                 2.8                 4.10  ...   \n",
       "3                    3.3                 1.6                 1.30  ...   \n",
       "4                    1.1                 3.6                 0.80  ...   \n",
       "...                  ...                 ...                  ...  ...   \n",
       "1995                 1.1                 1.2                 2.10  ...   \n",
       "1996                 2.7                 4.1                 5.85  ...   \n",
       "1997                 0.8                 2.6                 4.10  ...   \n",
       "1998                 1.7                 1.2                 2.00  ...   \n",
       "1999                 2.7                 1.8                 3.50  ...   \n",
       "\n",
       "      stress_level  physical_activity_hours_per_week  location_type  \\\n",
       "0             10.0                               0.7              2   \n",
       "1              6.0                               4.3              1   \n",
       "2              5.0                               3.1              1   \n",
       "3              5.0                               0.0              0   \n",
       "4              7.0                               3.0              2   \n",
       "...            ...                               ...            ...   \n",
       "1995           9.0                               0.0              2   \n",
       "1996           8.0                               2.7              2   \n",
       "1997           4.0                               6.5              2   \n",
       "1998           8.0                               2.6              2   \n",
       "1999          10.0                               6.3              2   \n",
       "\n",
       "      mental_health_score  uses_wellness_apps  eats_healthy  \\\n",
       "0                    32.0                 1.0           1.0   \n",
       "1                    75.0                 0.0           1.0   \n",
       "2                    22.0                 0.0           0.0   \n",
       "3                    22.0                 0.0           1.0   \n",
       "4                    64.0                 1.0           1.0   \n",
       "...                   ...                 ...           ...   \n",
       "1995                 62.0                 0.0           1.0   \n",
       "1996                 29.0                 0.0           0.0   \n",
       "1997                 54.0                 1.0           0.0   \n",
       "1998                 28.0                 0.0           0.0   \n",
       "1999                 59.0                 1.0           0.0   \n",
       "\n",
       "      caffeine_intake_mg_per_day  weekly_anxiety_score  \\\n",
       "0                          125.2                    13   \n",
       "1                          150.4                    19   \n",
       "2                          187.9                     7   \n",
       "3                           73.6                     7   \n",
       "4                          217.5                     8   \n",
       "...                          ...                   ...   \n",
       "1995                       164.9                    20   \n",
       "1996                       172.6                    15   \n",
       "1997                       101.3                     1   \n",
       "1998                       123.7                     1   \n",
       "1999                       173.1                     0   \n",
       "\n",
       "      weekly_depression_score  mindfulness_minutes_per_day  \n",
       "0                          15                          4.0  \n",
       "1                          18                          6.5  \n",
       "2                           3                          6.9  \n",
       "3                           2                          4.8  \n",
       "4                          10                          0.0  \n",
       "...                       ...                          ...  \n",
       "1995                       17                          4.9  \n",
       "1996                       15                         25.5  \n",
       "1997                       20                          9.5  \n",
       "1998                       11                         13.4  \n",
       "1999                       17                         10.0  \n",
       "\n",
       "[2000 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x= dc.drop(columns='mental_health_score')\n",
    "y= dc['mental_health_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t,x_te,y_t,y_te= train_test_split(x,y,test_size=.25,random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform only the selected columns\n",
    "x_t = scaler.fit_transform(x_t)\n",
    "x_te = scaler.fit_transform(x_te)\n",
    "#x_t[columns_to_scale] = scaler.fit_transform(x_t[columns_to_scale])\n",
    "#x_te[columns_to_scale] = scaler.fit_transform(x_te[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Performance:\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 17.3544\n",
      "  - MAE: 14.9520\n",
      "  - R^2 Score: 0.0103\n",
      "  - Training Time: 0.0162 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 17.9485\n",
      "  - MAE: 15.7154\n",
      "  - R^2 Score: -0.0134\n",
      "  - Prediction Time: 0.00134 seconds\n"
     ]
    }
   ],
   "source": [
    "# Initialize Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Timing the training process\n",
    "training_start = time.perf_counter()\n",
    "model = lr.fit(x_t, y_t)\n",
    "training_end = time.perf_counter()\n",
    "\n",
    "# Timing the prediction process\n",
    "prediction_start = time.perf_counter()\n",
    "y_pred_train = model.predict(x_t)\n",
    "y_pred_test = model.predict(x_te)\n",
    "prediction_end = time.perf_counter()\n",
    "\n",
    "# Calculate KPIs\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_t, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_te, y_pred_test))\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae_train = mean_absolute_error(y_t, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_te, y_pred_test)\n",
    "\n",
    "# R-squared score\n",
    "r2_train = r2_score(y_t, y_pred_train)\n",
    "r2_test = r2_score(y_te, y_pred_test)\n",
    "\n",
    "# Time metrics\n",
    "train_time = training_end - training_start\n",
    "prediction_time = prediction_end - prediction_start\n",
    "\n",
    "# Output metrics\n",
    "print(\"Linear Regression Model Performance:\")\n",
    "print(\"\\nTraining Set:\")\n",
    "print(f\"  - RMSE: {rmse_train:.4f}\")\n",
    "print(f\"  - MAE: {mae_train:.4f}\")\n",
    "print(f\"  - R^2 Score: {r2_train:.4f}\")\n",
    "print(f\"  - Training Time: {train_time:.4f} seconds\")\n",
    "\n",
    "print(\"\\nTesting Set:\")\n",
    "print(f\"  - RMSE: {rmse_test:.4f}\")\n",
    "print(f\"  - MAE: {mae_test:.4f}\")\n",
    "print(f\"  - R^2 Score: {r2_test:.4f}\")\n",
    "print(f\"  - Prediction Time: {prediction_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.294\n",
      "17.847033288319626\n"
     ]
    }
   ],
   "source": [
    "print(y_te.mean())\n",
    "print(y_te.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Variable: mental_health_score\n",
    "Mean: 49.294\n",
    "\n",
    "Standard Deviation: 17.847\n",
    "\n",
    "Model Evaluation Metric: Root Mean Squared Error (RMSE)\n",
    "RMSE Value: 23939.3614\n",
    "\n",
    "Interpretation:\n",
    "1. Magnitude and Practical Relevance\n",
    "The RMSE is extremely large compared to both the mean (49.294) and standard deviation (17.847) of the target variable.\n",
    "\n",
    "This suggests that the model's predictions are highly inaccurate. An RMSE of 23939.3614, when the average value of the target is only around 49, means predictions are orders of magnitude off.\n",
    "\n",
    "2. Relative Error Analysis\n",
    "To assess model performance, compare RMSE with the mean:\n",
    "\n",
    "Relative RMSE = \n",
    "23939.36\n",
    "49.294\n",
    "â‰ˆ\n",
    "485.5\n",
    "49.294\n",
    "23939.36\n",
    "â€‹\n",
    " â‰ˆ485.5\n",
    "This means the model's predictions deviate by roughly 485 times the average mental health score, which is unacceptably high.\n",
    "\n",
    "Similarly, comparing RMSE to the standard deviation:\n",
    "\n",
    "Relative to standard deviation = \n",
    "23939.36\n",
    "17.847\n",
    "â‰ˆ\n",
    "1341.0\n",
    "17.847\n",
    "23939.36\n",
    "â€‹\n",
    " â‰ˆ1341.0\n",
    "This indicates the error is far beyond the natural variability in the data.\n",
    "\n",
    "Conclusion:\n",
    "The model's RMSE is too high relative to both the mean and standard deviation of the mental_health_score.\n",
    "\n",
    "This likely points to a serious issue in model training, target leakage, incorrect units, or data preprocessing errors.\n",
    "\n",
    "You should double-check:\n",
    "\n",
    "Whether the target variable was scaled or transformed.\n",
    "\n",
    "That the model is not predicting an unrelated or mismatched target.\n",
    "\n",
    "That the metric wasn't accidentally computed on a misaligned scale (e.g., predicting dollars instead of a 0â€“100 score).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define models and parameter grids for GridSearchCV\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1, 10, 100,200,300,400,500]}\n",
    "ridge_grid = GridSearchCV(estimator=ridge, param_grid=ridge_params, \n",
    "                          cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# Lasso Regression Hypertuning\n",
    "lasso_grid = GridSearchCV(estimator=lasso, param_grid=lasso_params, \n",
    "                          cv=5, scoring='neg_mean_squared_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge and Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Ridge Model: {'alpha': 100}\n",
      "\n",
      "Best Lasso Model: {'alpha': 10}\n"
     ]
    }
   ],
   "source": [
    "ridge_grid.fit(x_t, y_t)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "print(\"\\nBest Ridge Model:\", ridge_grid.best_params_)\n",
    "\n",
    "\n",
    "lasso_grid.fit(x_t, y_t)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "print(\"\\nBest Lasso Model:\", lasso_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Ridge Model:\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 17.3548\n",
      "  - MAE: 14.9554\n",
      "  - R^2 Score: 0.0102\n",
      "  - Training Time: 0.0015 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 17.9350\n",
      "  - MAE: 15.7046\n",
      "  - R^2 Score: -0.0119\n",
      "  - Prediction Time: 0.00069 seconds\n",
      "\n",
      "Evaluating Lasso Model:\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 17.4440\n",
      "  - MAE: 15.0515\n",
      "  - R^2 Score: 0.0000\n",
      "  - Training Time: 0.0022 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 17.8355\n",
      "  - MAE: 15.6291\n",
      "  - R^2 Score: -0.0007\n",
      "  - Prediction Time: 0.00100 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best models\n",
    "best_models = {'Ridge': best_ridge, 'Lasso': best_lasso}\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\nEvaluating {model_name} Model:\")\n",
    "\n",
    "    # Timing the training process\n",
    "    training_start = time.perf_counter()\n",
    "    model.fit(x_t, y_t)\n",
    "    training_end = time.perf_counter()\n",
    "    \n",
    "    # Timing the prediction process\n",
    "    prediction_start = time.perf_counter()\n",
    "    y_pred_train = model.predict(x_t)\n",
    "    y_pred_test = model.predict(x_te)\n",
    "    prediction_end = time.perf_counter()\n",
    "\n",
    "    # Calculate KPIs\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_t, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_te, y_pred_test))\n",
    "    mae_train = mean_absolute_error(y_t, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_te, y_pred_test)\n",
    "    r2_train = r2_score(y_t, y_pred_train)\n",
    "    r2_test = r2_score(y_te, y_pred_test)\n",
    "\n",
    "    # Time metrics\n",
    "    train_time = training_end - training_start\n",
    "    prediction_time = prediction_end - prediction_start\n",
    "\n",
    "    # Output metrics\n",
    "    print(\"\\nTraining Set:\")\n",
    "    print(f\"  - RMSE: {rmse_train:.4f}\")\n",
    "    print(f\"  - MAE: {mae_train:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_train:.4f}\")\n",
    "    print(f\"  - Training Time: {train_time:.4f} seconds\")\n",
    "\n",
    "    print(\"\\nTesting Set:\")\n",
    "    print(f\"  - RMSE: {rmse_test:.4f}\")\n",
    "    print(f\"  - MAE: {mae_test:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_test:.4f}\")\n",
    "    print(f\"  - Prediction Time: {prediction_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to run all the models seperatlty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, x_t, y_t, x_te, y_te):\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "\n",
    "    # Training\n",
    "    training_start = time.perf_counter()\n",
    "    model.fit(x_t, y_t)\n",
    "    training_end = time.perf_counter()\n",
    "\n",
    "    # Prediction\n",
    "    prediction_start = time.perf_counter()\n",
    "    y_pred_train = model.predict(x_t)\n",
    "    y_pred_test = model.predict(x_te)\n",
    "    prediction_end = time.perf_counter()\n",
    "\n",
    "    # Metrics\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_t, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_te, y_pred_test))\n",
    "\n",
    "    mae_train = mean_absolute_error(y_t, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_te, y_pred_test)\n",
    "\n",
    "    r2_train = r2_score(y_t, y_pred_train)\n",
    "    r2_test = r2_score(y_te, y_pred_test)\n",
    "\n",
    "    train_time = training_end - training_start\n",
    "    prediction_time = prediction_end - prediction_start\n",
    "\n",
    "    # Output\n",
    "    print(\"\\nTraining Set:\")\n",
    "    print(f\"  - RMSE: {rmse_train:.4f}\")\n",
    "    print(f\"  - MAE: {mae_train:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_train:.4f}\")\n",
    "    print(f\"  - Training Time: {train_time:.4f} seconds\")\n",
    "\n",
    "    print(\"\\nTesting Set:\")\n",
    "    print(f\"  - RMSE: {rmse_test:.4f}\")\n",
    "    print(f\"  - MAE: {mae_test:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_test:.4f}\")\n",
    "    print(f\"  - Prediction Time: {prediction_time:.5f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Support Vector Machine =====\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 16.8954\n",
      "  - MAE: 14.3899\n",
      "  - R^2 Score: 0.0619\n",
      "  - Training Time: 0.1069 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 17.9688\n",
      "  - MAE: 15.7236\n",
      "  - R^2 Score: -0.0157\n",
      "  - Prediction Time: 0.23183 seconds\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = SVR()\n",
    "evaluate_model(svm_model, \"Support Vector Machine\", x_t, y_t, x_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== K-Nearest Neighbors =====\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 15.4634\n",
      "  - MAE: 12.8645\n",
      "  - R^2 Score: 0.2142\n",
      "  - Training Time: 0.0012 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 19.8890\n",
      "  - MAE: 17.0400\n",
      "  - R^2 Score: -0.2444\n",
      "  - Prediction Time: 0.23565 seconds\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn_model = KNeighborsRegressor()\n",
    "evaluate_model(knn_model, \"K-Nearest Neighbors\", x_t, y_t, x_te, y_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Decision Tree =====\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 0.0000\n",
      "  - MAE: 0.0000\n",
      "  - R^2 Score: 1.0000\n",
      "  - Training Time: 0.0322 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 26.1623\n",
      "  - MAE: 21.4300\n",
      "  - R^2 Score: -1.1532\n",
      "  - Prediction Time: 0.00073 seconds\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "evaluate_model(tree_model, \"Decision Tree\", x_t, y_t, x_te, y_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Random Forest =====\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 6.6018\n",
      "  - MAE: 5.5907\n",
      "  - R^2 Score: 0.8568\n",
      "  - Training Time: 1.5907 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 18.2149\n",
      "  - MAE: 15.8943\n",
      "  - R^2 Score: -0.0437\n",
      "  - Prediction Time: 0.02850 seconds\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "evaluate_model(rf_model, \"Random Forest\", x_t, y_t, x_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function with Best Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, x_t, y_t, x_te, y_te):\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "\n",
    "    # Training\n",
    "    training_start = time.perf_counter()\n",
    "    model.fit(x_t, y_t)\n",
    "    training_end = time.perf_counter()\n",
    "\n",
    "    best_model = model.best_estimator_ if hasattr(model, \"best_estimator_\") else model\n",
    "\n",
    "    # Prediction\n",
    "    prediction_start = time.perf_counter()\n",
    "    y_pred_train = best_model.predict(x_t)\n",
    "    y_pred_test = best_model.predict(x_te)\n",
    "    prediction_end = time.perf_counter()\n",
    "\n",
    "    # Metrics\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_t, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_te, y_pred_test))\n",
    "\n",
    "    mae_train = mean_absolute_error(y_t, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_te, y_pred_test)\n",
    "\n",
    "    r2_train = r2_score(y_t, y_pred_train)\n",
    "    r2_test = r2_score(y_te, y_pred_test)\n",
    "\n",
    "    train_time = training_end - training_start\n",
    "    prediction_time = prediction_end - prediction_start\n",
    "\n",
    "    # Output\n",
    "    print(\"\\nBest Parameters:\", model.best_params_ if hasattr(model, \"best_params_\") else \"Default\")\n",
    "    print(\"\\nTraining Set:\")\n",
    "    print(f\"  - RMSE: {rmse_train:.4f}\")\n",
    "    print(f\"  - MAE: {mae_train:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_train:.4f}\")\n",
    "    print(f\"  - Training Time: {train_time:.4f} seconds\")\n",
    "\n",
    "    print(\"\\nTesting Set:\")\n",
    "    print(f\"  - RMSE: {rmse_test:.4f}\")\n",
    "    print(f\"  - MAE: {mae_test:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_test:.4f}\")\n",
    "    print(f\"  - Prediction Time: {prediction_time:.5f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Support Vector Machine (SVM) =====\n",
      "\n",
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 17.3779\n",
      "  - MAE: 14.9739\n",
      "  - R^2 Score: 0.0076\n",
      "  - Training Time: 0.7760 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 17.8509\n",
      "  - MAE: 15.6494\n",
      "  - R^2 Score: -0.0024\n",
      "  - Prediction Time: 0.24657 seconds\n",
      "\n",
      "===== K-Nearest Neighbors (KNN) =====\n",
      "\n",
      "Best Parameters: {'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 0.0000\n",
      "  - MAE: 0.0000\n",
      "  - R^2 Score: 1.0000\n",
      "  - Training Time: 0.0670 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 18.8566\n",
      "  - MAE: 16.1676\n",
      "  - R^2 Score: -0.1186\n",
      "  - Prediction Time: 0.02000 seconds\n",
      "\n",
      "===== Decision Tree =====\n",
      "\n",
      "Best Parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 16.5455\n",
      "  - MAE: 14.0127\n",
      "  - R^2 Score: 0.1004\n",
      "  - Training Time: 0.1815 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 18.8191\n",
      "  - MAE: 16.3478\n",
      "  - R^2 Score: -0.1141\n",
      "  - Prediction Time: 0.00041 seconds\n",
      "\n",
      "===== Random Forest =====\n",
      "\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 11.1592\n",
      "  - MAE: 9.5313\n",
      "  - R^2 Score: 0.5908\n",
      "  - Training Time: 5.7074 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 18.1275\n",
      "  - MAE: 15.8480\n",
      "  - R^2 Score: -0.0337\n",
      "  - Prediction Time: 0.02017 seconds\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "svm_grid = GridSearchCV(SVR(), svm_params, cv=3, scoring='neg_root_mean_squared_log_error', n_jobs=-1)\n",
    "evaluate_model(svm_grid, \"Support Vector Machine (SVM)\", x_t, y_t, x_te, y_te)\n",
    "\n",
    "# KNN\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # Manhattan or Euclidean\n",
    "}\n",
    "knn_grid = GridSearchCV(KNeighborsRegressor(), knn_params, cv=3, scoring='neg_root_mean_squared_log_error', n_jobs=-1)\n",
    "evaluate_model(knn_grid, \"K-Nearest Neighbors (KNN)\", x_t, y_t, x_te, y_te)\n",
    "\n",
    "# Decision Tree\n",
    "tree_params = {\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "tree_grid = GridSearchCV(DecisionTreeRegressor(random_state=42), tree_params, cv=3, scoring='neg_root_mean_squared_log_error', n_jobs=-1)\n",
    "evaluate_model(tree_grid, \"Decision Tree\", x_t, y_t, x_te, y_te)\n",
    "\n",
    "# Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=3, scoring='neg_root_mean_squared_log_error', n_jobs=-1)\n",
    "evaluate_model(rf_grid, \"Random Forest\", x_t, y_t, x_te, y_te)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
