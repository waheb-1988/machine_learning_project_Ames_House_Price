{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Context:\n",
    "Explore the relationship between screen time and mental health. Your goal is to understand\n",
    "the structure of the dataset, perform analysis, build predictive models, and interpret the\n",
    "results. You need treat the mental_health_score either as a continuous variable (regression)\n",
    "or convert it into a binary classification target:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pathlib\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#https://medium.com/@prosun.csedu/polynomialfeatures-is-a-preprocessing-tool-provided-by-the-scikit-learn-library-in-python-that-is-84118adea049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Abdelouaheb\\perso\\Data_science_2024_projects\\2025\\machine_learning_project_Ames_House_Price\\test_solution\n",
      "c:\\Abdelouaheb\\perso\\Data_science_2024_projects\\2025\\machine_learning_project_Ames_House_Price\\test_solution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>daily_screen_time_hours</th>\n",
       "      <th>phone_usage_hours</th>\n",
       "      <th>laptop_usage_hours</th>\n",
       "      <th>tablet_usage_hours</th>\n",
       "      <th>tv_usage_hours</th>\n",
       "      <th>social_media_hours</th>\n",
       "      <th>work_related_hours</th>\n",
       "      <th>...</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>physical_activity_hours_per_week</th>\n",
       "      <th>location_type</th>\n",
       "      <th>mental_health_score</th>\n",
       "      <th>uses_wellness_apps</th>\n",
       "      <th>eats_healthy</th>\n",
       "      <th>caffeine_intake_mg_per_day</th>\n",
       "      <th>weekly_anxiety_score</th>\n",
       "      <th>weekly_depression_score</th>\n",
       "      <th>mindfulness_minutes_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Urban</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>64</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.4</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>41</td>\n",
       "      <td>Other</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187.9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_4</td>\n",
       "      <td>27</td>\n",
       "      <td>Other</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_5</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>217.5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  age  gender  daily_screen_time_hours  phone_usage_hours  \\\n",
       "0  user_1   51  Female                      4.8                3.4   \n",
       "1  user_2   64    Male                      3.9                3.5   \n",
       "2  user_3   41   Other                     10.5                2.1   \n",
       "3  user_4   27   Other                      8.8                0.0   \n",
       "4  user_5   55    Male                      5.9                1.7   \n",
       "\n",
       "   laptop_usage_hours  tablet_usage_hours  tv_usage_hours  social_media_hours  \\\n",
       "0                 1.3                 1.6             1.6                 4.1   \n",
       "1                 1.8                 0.9             2.0                 2.7   \n",
       "2                 2.6                 0.7             2.2                 3.0   \n",
       "3                 0.0                 0.7             2.5                 3.3   \n",
       "4                 1.1                 1.5             1.6                 1.1   \n",
       "\n",
       "   work_related_hours  ...  stress_level  physical_activity_hours_per_week  \\\n",
       "0                 2.0  ...            10                               0.7   \n",
       "1                 3.1  ...             6                               4.3   \n",
       "2                 2.8  ...             5                               3.1   \n",
       "3                 1.6  ...             5                               0.0   \n",
       "4                 3.6  ...             7                               3.0   \n",
       "\n",
       "   location_type  mental_health_score  uses_wellness_apps  eats_healthy  \\\n",
       "0          Urban                   32                   1             1   \n",
       "1       Suburban                   75                   0             1   \n",
       "2       Suburban                   22                   0             0   \n",
       "3          Rural                   22                   0             1   \n",
       "4          Urban                   64                   1             1   \n",
       "\n",
       "   caffeine_intake_mg_per_day weekly_anxiety_score  weekly_depression_score  \\\n",
       "0                       125.2                   13                       15   \n",
       "1                       150.4                   19                       18   \n",
       "2                       187.9                    7                        3   \n",
       "3                        73.6                    7                        2   \n",
       "4                       217.5                    8                       10   \n",
       "\n",
       "   mindfulness_minutes_per_day  \n",
       "0                          4.0  \n",
       "1                          6.5  \n",
       "2                          6.9  \n",
       "3                          4.8  \n",
       "4                          0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(file_name : str )  -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dir_folder = pathlib.Path().cwd()\n",
    "        print(dir_folder)\n",
    "        file_path  = dir_folder\n",
    "        print(file_path)\n",
    "        df = pd.read_csv(os.path.join(file_path/file_name))\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at '{file_name}' was not found.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "         print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "df = read_file('digital_diet_mental_health.csv')      \n",
    "  \n",
    "df.head()   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def impute_dataframe(df, strategy_num=\"mean\", strategy_cat=\"most_frequent\"):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a DataFrame separately for numerical and categorical columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame.\n",
    "    strategy_num (str): Strategy for imputing numerical columns (default=\"mean\").\n",
    "    strategy_cat (str): Strategy for imputing categorical columns (default=\"most_frequent\").\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with imputed values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Separate numerical and categorical columns\n",
    "    num_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "    cat_cols = df.select_dtypes(exclude=[\"number\"]).columns\n",
    "\n",
    "    # Impute numerical columns\n",
    "    if len(num_cols) > 0:\n",
    "        num_imputer = SimpleImputer(strategy=strategy_num)\n",
    "        df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "\n",
    "    # Impute categorical columns\n",
    "    if len(cat_cols) > 0:\n",
    "        cat_imputer = SimpleImputer(strategy=strategy_cat)\n",
    "        df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing duplicates rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df, subset=None, keep='first', inplace=False):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows from the DataFrame and provides a summary of duplicates.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame from which to remove duplicates.\n",
    "        subset (list): List of columns to consider for duplicate checking. \n",
    "                       If None, checks all columns.\n",
    "        keep (str): Which duplicates to keep. Options:\n",
    "            - 'first': Keep the first occurrence (default).\n",
    "            - 'last': Keep the last occurrence.\n",
    "            - 'none': Drop all duplicates.\n",
    "        inplace (bool): If True, modifies the original DataFrame. \n",
    "                        If False, returns a new DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed (if inplace=False).\n",
    "    \"\"\"\n",
    "    if keep not in ['first', 'last', 'none']:\n",
    "        raise ValueError(\"keep must be one of 'first', 'last', or 'none'.\")\n",
    "    \n",
    "    # Count duplicates before removal\n",
    "    total_rows = len(df)\n",
    "    duplicate_rows = df.duplicated(subset=subset, keep=False).sum()\n",
    "    percentage_duplicates = (duplicate_rows / total_rows) * 100\n",
    "    \n",
    "    print(f\"Total Rows: {total_rows}\")\n",
    "    print(f\"Duplicate Rows: {duplicate_rows} ({percentage_duplicates:.2f}%)\")\n",
    "    \n",
    "    if duplicate_rows == 0:\n",
    "        print(\"No duplicates found. No rows removed.\")\n",
    "        return df if not inplace else None\n",
    "    \n",
    "    # Handle duplicate removal\n",
    "    if keep == 'none':\n",
    "        # Drop all duplicates and keep only unique rows\n",
    "        duplicated_mask = df.duplicated(subset=subset, keep=False)\n",
    "        result = df[~duplicated_mask]\n",
    "    else:\n",
    "        # Use pandas built-in drop_duplicates\n",
    "        result = df.drop_duplicates(subset=subset, keep=keep)\n",
    "    \n",
    "    # Count duplicates after removal\n",
    "    remaining_rows = len(result)\n",
    "    rows_removed = total_rows - remaining_rows\n",
    "    \n",
    "    print(f\"Rows Removed: {rows_removed}\")\n",
    "    print(f\"Remaining Rows: {remaining_rows}\")\n",
    "    \n",
    "    if rows_removed > 0:\n",
    "        print(\"Duplicates successfully removed.\")\n",
    "    else:\n",
    "        print(\"No duplicates were removed.\")\n",
    "    \n",
    "    if inplace:\n",
    "        df.drop_duplicates(subset=subset, keep=keep, inplace=True)\n",
    "    else:\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 2000\n",
      "Duplicate Rows: 0 (0.00%)\n",
      "No duplicates found. No rows removed.\n"
     ]
    }
   ],
   "source": [
    "dm=remove_duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handles outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, numerical_columns=None, method='IQR', verbose=True):\n",
    "    \"\"\"\n",
    "    Handles outliers in continuous numerical variables using the specified method.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        numerical_columns (list): List of numerical columns to check for outliers. If None, auto-selects all numerical columns.\n",
    "        method (str): Method to handle outliers ('IQR' or 'Z-Score'). Default is 'IQR'.\n",
    "        verbose (bool): If True, displays outlier statistics.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with outliers handled.\n",
    "    \"\"\"\n",
    "    # Select numerical columns if not provided\n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    # Iterate over each numerical column\n",
    "    for col in numerical_columns:\n",
    "        if col in df.columns:\n",
    "            if method == 'IQR':\n",
    "                # Calculate Q1, Q3, and IQR\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                \n",
    "                # Count and handle outliers\n",
    "                outliers = ((df[col] < lower_bound) | (df[col] > upper_bound))\n",
    "                num_outliers = outliers.sum()\n",
    "                \n",
    "                # Option 1: Capping\n",
    "                df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "                df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"[INFO] Outliers handled in '{col}' using IQR:\")\n",
    "                    print(f\"         - Number of Outliers: {num_outliers}\")\n",
    "                    print(f\"         - Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
    "            \n",
    "            elif method == 'Z-Score':\n",
    "                # Alternative method (if needed)\n",
    "                mean = df[col].mean()\n",
    "                std_dev = df[col].std()\n",
    "                threshold = 3  # Standard deviation threshold\n",
    "                \n",
    "                # Count and handle outliers\n",
    "                outliers = ((df[col] < (mean - threshold * std_dev)) | (df[col] > (mean + threshold * std_dev)))\n",
    "                num_outliers = outliers.sum()\n",
    "                \n",
    "                # Option 1: Capping\n",
    "                lower_bound = mean - threshold * std_dev\n",
    "                upper_bound = mean + threshold * std_dev\n",
    "                df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "                df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"[INFO] Outliers handled in '{col}' using Z-Score:\")\n",
    "                    print(f\"         - Number of Outliers: {num_outliers}\")\n",
    "                    print(f\"         - Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Outliers handled in 'age' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -11.5, Upper Bound: 88.5\n",
      "[INFO] Outliers handled in 'daily_screen_time_hours' using IQR:\n",
      "         - Number of Outliers: 18\n",
      "         - Lower Bound: 0.7625000000000002, Upper Bound: 11.2625\n",
      "[INFO] Outliers handled in 'phone_usage_hours' using IQR:\n",
      "         - Number of Outliers: 6\n",
      "         - Lower Bound: -1.0, Upper Bound: 7.0\n",
      "[INFO] Outliers handled in 'laptop_usage_hours' using IQR:\n",
      "         - Number of Outliers: 7\n",
      "         - Lower Bound: -0.8, Upper Bound: 4.800000000000001\n",
      "[INFO] Outliers handled in 'tablet_usage_hours' using IQR:\n",
      "         - Number of Outliers: 4\n",
      "         - Lower Bound: -0.45000000000000007, Upper Bound: 2.35\n",
      "[INFO] Outliers handled in 'tv_usage_hours' using IQR:\n",
      "         - Number of Outliers: 6\n",
      "         - Lower Bound: -1.3, Upper Bound: 4.300000000000001\n",
      "[INFO] Outliers handled in 'social_media_hours' using IQR:\n",
      "         - Number of Outliers: 9\n",
      "         - Lower Bound: -1.2, Upper Bound: 5.199999999999999\n",
      "[INFO] Outliers handled in 'work_related_hours' using IQR:\n",
      "         - Number of Outliers: 5\n",
      "         - Lower Bound: -1.2, Upper Bound: 5.199999999999999\n",
      "[INFO] Outliers handled in 'entertainment_hours' using IQR:\n",
      "         - Number of Outliers: 5\n",
      "         - Lower Bound: -0.9499999999999997, Upper Bound: 5.85\n",
      "[INFO] Outliers handled in 'gaming_hours' using IQR:\n",
      "         - Number of Outliers: 9\n",
      "         - Lower Bound: -1.3499999999999996, Upper Bound: 3.8499999999999996\n",
      "[INFO] Outliers handled in 'sleep_duration_hours' using IQR:\n",
      "         - Number of Outliers: 11\n",
      "         - Lower Bound: 3.15, Upper Bound: 9.950000000000001\n",
      "[INFO] Outliers handled in 'sleep_quality' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -4.5, Upper Bound: 15.5\n",
      "[INFO] Outliers handled in 'mood_rating' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -4.5, Upper Bound: 15.5\n",
      "[INFO] Outliers handled in 'stress_level' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -4.5, Upper Bound: 15.5\n",
      "[INFO] Outliers handled in 'physical_activity_hours_per_week' using IQR:\n",
      "         - Number of Outliers: 6\n",
      "         - Lower Bound: -2.6, Upper Bound: 8.600000000000001\n",
      "[INFO] Outliers handled in 'mental_health_score' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -8.875, Upper Bound: 108.125\n",
      "[INFO] Outliers handled in 'uses_wellness_apps' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -1.5, Upper Bound: 2.5\n",
      "[INFO] Outliers handled in 'eats_healthy' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -1.5, Upper Bound: 2.5\n",
      "[INFO] Outliers handled in 'caffeine_intake_mg_per_day' using IQR:\n",
      "         - Number of Outliers: 14\n",
      "         - Lower Bound: 13.700000000000031, Upper Bound: 280.9\n",
      "[INFO] Outliers handled in 'weekly_anxiety_score' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -10.0, Upper Bound: 30.0\n",
      "[INFO] Outliers handled in 'weekly_depression_score' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -10.0, Upper Bound: 30.0\n",
      "[INFO] Outliers handled in 'mindfulness_minutes_per_day' using IQR:\n",
      "         - Number of Outliers: 6\n",
      "         - Lower Bound: -11.450000000000001, Upper Bound: 32.150000000000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS TUF\\AppData\\Local\\Temp\\ipykernel_14504\\2635347732.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-11.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[col] < lower_bound, col] = lower_bound\n",
      "C:\\Users\\ASUS TUF\\AppData\\Local\\Temp\\ipykernel_14504\\2635347732.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-4.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[col] < lower_bound, col] = lower_bound\n",
      "C:\\Users\\ASUS TUF\\AppData\\Local\\Temp\\ipykernel_14504\\2635347732.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-4.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[col] < lower_bound, col] = lower_bound\n",
      "C:\\Users\\ASUS TUF\\AppData\\Local\\Temp\\ipykernel_14504\\2635347732.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-4.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[col] < lower_bound, col] = lower_bound\n",
      "C:\\Users\\ASUS TUF\\AppData\\Local\\Temp\\ipykernel_14504\\2635347732.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-8.875' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[col] < lower_bound, col] = lower_bound\n",
      "C:\\Users\\ASUS TUF\\AppData\\Local\\Temp\\ipykernel_14504\\2635347732.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[col] < lower_bound, col] = lower_bound\n",
      "C:\\Users\\ASUS TUF\\AppData\\Local\\Temp\\ipykernel_14504\\2635347732.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[col] < lower_bound, col] = lower_bound\n"
     ]
    }
   ],
   "source": [
    "dc=handle_outliers(dm, numerical_columns=None, method='IQR', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data type conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   user_id                           2000 non-null   object \n",
      " 1   age                               2000 non-null   float64\n",
      " 2   gender                            2000 non-null   object \n",
      " 3   daily_screen_time_hours           2000 non-null   float64\n",
      " 4   phone_usage_hours                 2000 non-null   float64\n",
      " 5   laptop_usage_hours                2000 non-null   float64\n",
      " 6   tablet_usage_hours                2000 non-null   float64\n",
      " 7   tv_usage_hours                    2000 non-null   float64\n",
      " 8   social_media_hours                2000 non-null   float64\n",
      " 9   work_related_hours                2000 non-null   float64\n",
      " 10  entertainment_hours               2000 non-null   float64\n",
      " 11  gaming_hours                      2000 non-null   float64\n",
      " 12  sleep_duration_hours              2000 non-null   float64\n",
      " 13  sleep_quality                     2000 non-null   float64\n",
      " 14  mood_rating                       2000 non-null   float64\n",
      " 15  stress_level                      2000 non-null   float64\n",
      " 16  physical_activity_hours_per_week  2000 non-null   float64\n",
      " 17  location_type                     2000 non-null   object \n",
      " 18  mental_health_score               2000 non-null   float64\n",
      " 19  uses_wellness_apps                2000 non-null   float64\n",
      " 20  eats_healthy                      2000 non-null   float64\n",
      " 21  caffeine_intake_mg_per_day        2000 non-null   float64\n",
      " 22  weekly_anxiety_score              2000 non-null   int64  \n",
      " 23  weekly_depression_score           2000 non-null   int64  \n",
      " 24  mindfulness_minutes_per_day       2000 non-null   float64\n",
      "dtypes: float64(20), int64(2), object(3)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'gender', 'location_type']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_object_columns(df):\n",
    "    \"\"\"\n",
    "    Cette fonction retourne la liste des colonnes de type 'object' dans un DataFrame.\n",
    "    \n",
    "    Paramètres :\n",
    "    df (pd.DataFrame) : Le DataFrame à analyser.\n",
    "    \n",
    "    Retour :\n",
    "    list : Liste des noms de colonnes de type 'object'.\n",
    "    \"\"\"\n",
    "    return df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# df = pd.read_csv('ton_fichier.csv')\n",
    "object_columns = get_object_columns(dc)\n",
    "print(object_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = dc.drop('user_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_columns(df, columns=object_columns, verbose=True):\n",
    "    \"\"\"\n",
    "    Performs Label Encoding on specified categorical columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to encode.\n",
    "        columns (list): List of column names to be label encoded.\n",
    "        verbose (bool): If True, displays the label mappings.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with encoded columns.\n",
    "    \"\"\"\n",
    "    # Loop through the specified columns and encode them\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            \n",
    "            # Display label mapping\n",
    "            if verbose:\n",
    "                mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(f\"\\n[INFO] Label Encoding for '{col}': {mapping}\")\n",
    "        else:\n",
    "            print(f\"[WARNING] Column '{col}' not found in DataFrame.\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Column 'user_id' not found in DataFrame.\n",
      "\n",
      "[INFO] Label Encoding for 'gender': {'Female': 0, 'Male': 1, 'Other': 2}\n",
      "\n",
      "[INFO] Label Encoding for 'location_type': {'Rural': 0, 'Suburban': 1, 'Urban': 2}\n"
     ]
    }
   ],
   "source": [
    "dc=label_encode_columns(dc, columns=object_columns, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>daily_screen_time_hours</th>\n",
       "      <th>phone_usage_hours</th>\n",
       "      <th>laptop_usage_hours</th>\n",
       "      <th>tablet_usage_hours</th>\n",
       "      <th>tv_usage_hours</th>\n",
       "      <th>social_media_hours</th>\n",
       "      <th>work_related_hours</th>\n",
       "      <th>entertainment_hours</th>\n",
       "      <th>...</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>physical_activity_hours_per_week</th>\n",
       "      <th>location_type</th>\n",
       "      <th>mental_health_score</th>\n",
       "      <th>uses_wellness_apps</th>\n",
       "      <th>eats_healthy</th>\n",
       "      <th>caffeine_intake_mg_per_day</th>\n",
       "      <th>weekly_anxiety_score</th>\n",
       "      <th>weekly_depression_score</th>\n",
       "      <th>mindfulness_minutes_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.4</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.10</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.9</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.6</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender  daily_screen_time_hours  phone_usage_hours  \\\n",
       "0     51.0       0                      4.8                3.4   \n",
       "1     64.0       1                      3.9                3.5   \n",
       "2     41.0       2                     10.5                2.1   \n",
       "3     27.0       2                      8.8                0.0   \n",
       "4     55.0       1                      5.9                1.7   \n",
       "...    ...     ...                      ...                ...   \n",
       "1995  58.0       0                      5.6                4.0   \n",
       "1996  62.0       0                      3.9                3.1   \n",
       "1997  64.0       0                      7.4                3.0   \n",
       "1998  19.0       1                      4.2                4.4   \n",
       "1999  15.0       0                      4.5                3.6   \n",
       "\n",
       "      laptop_usage_hours  tablet_usage_hours  tv_usage_hours  \\\n",
       "0                    1.3                 1.6             1.6   \n",
       "1                    1.8                 0.9             2.0   \n",
       "2                    2.6                 0.7             2.2   \n",
       "3                    0.0                 0.7             2.5   \n",
       "4                    1.1                 1.5             1.6   \n",
       "...                  ...                 ...             ...   \n",
       "1995                 2.5                 0.3             1.5   \n",
       "1996                 1.0                 1.5             1.1   \n",
       "1997                 0.0                 1.4             0.9   \n",
       "1998                 2.3                 0.9             1.4   \n",
       "1999                 1.2                 1.4             1.8   \n",
       "\n",
       "      social_media_hours  work_related_hours  entertainment_hours  ...  \\\n",
       "0                    4.1                 2.0                 1.00  ...   \n",
       "1                    2.7                 3.1                 1.00  ...   \n",
       "2                    3.0                 2.8                 4.10  ...   \n",
       "3                    3.3                 1.6                 1.30  ...   \n",
       "4                    1.1                 3.6                 0.80  ...   \n",
       "...                  ...                 ...                  ...  ...   \n",
       "1995                 1.1                 1.2                 2.10  ...   \n",
       "1996                 2.7                 4.1                 5.85  ...   \n",
       "1997                 0.8                 2.6                 4.10  ...   \n",
       "1998                 1.7                 1.2                 2.00  ...   \n",
       "1999                 2.7                 1.8                 3.50  ...   \n",
       "\n",
       "      stress_level  physical_activity_hours_per_week  location_type  \\\n",
       "0             10.0                               0.7              2   \n",
       "1              6.0                               4.3              1   \n",
       "2              5.0                               3.1              1   \n",
       "3              5.0                               0.0              0   \n",
       "4              7.0                               3.0              2   \n",
       "...            ...                               ...            ...   \n",
       "1995           9.0                               0.0              2   \n",
       "1996           8.0                               2.7              2   \n",
       "1997           4.0                               6.5              2   \n",
       "1998           8.0                               2.6              2   \n",
       "1999          10.0                               6.3              2   \n",
       "\n",
       "      mental_health_score  uses_wellness_apps  eats_healthy  \\\n",
       "0                    32.0                 1.0           1.0   \n",
       "1                    75.0                 0.0           1.0   \n",
       "2                    22.0                 0.0           0.0   \n",
       "3                    22.0                 0.0           1.0   \n",
       "4                    64.0                 1.0           1.0   \n",
       "...                   ...                 ...           ...   \n",
       "1995                 62.0                 0.0           1.0   \n",
       "1996                 29.0                 0.0           0.0   \n",
       "1997                 54.0                 1.0           0.0   \n",
       "1998                 28.0                 0.0           0.0   \n",
       "1999                 59.0                 1.0           0.0   \n",
       "\n",
       "      caffeine_intake_mg_per_day  weekly_anxiety_score  \\\n",
       "0                          125.2                    13   \n",
       "1                          150.4                    19   \n",
       "2                          187.9                     7   \n",
       "3                           73.6                     7   \n",
       "4                          217.5                     8   \n",
       "...                          ...                   ...   \n",
       "1995                       164.9                    20   \n",
       "1996                       172.6                    15   \n",
       "1997                       101.3                     1   \n",
       "1998                       123.7                     1   \n",
       "1999                       173.1                     0   \n",
       "\n",
       "      weekly_depression_score  mindfulness_minutes_per_day  \n",
       "0                          15                          4.0  \n",
       "1                          18                          6.5  \n",
       "2                           3                          6.9  \n",
       "3                           2                          4.8  \n",
       "4                          10                          0.0  \n",
       "...                       ...                          ...  \n",
       "1995                       17                          4.9  \n",
       "1996                       15                         25.5  \n",
       "1997                       20                          9.5  \n",
       "1998                       11                         13.4  \n",
       "1999                       17                         10.0  \n",
       "\n",
       "[2000 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary target based on the median of &#39;mental_health_score&#39;\n",
    "median_score = 30\n",
    "dc['mental_health_binary'] = (dc['mental_health_score'] >= median_score).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = dc.drop('mental_health_score', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x= dc.drop(columns='mental_health_binary')\n",
    "y= dc['mental_health_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t,x_te,y_t,y_te= train_test_split(x,y,test_size=.25,random_state=20,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform only the selected columns\n",
    "x_t = scaler.fit_transform(x_t)\n",
    "x_te = scaler.fit_transform(x_te)\n",
    "#x_t[columns_to_scale] = scaler.fit_transform(x_t[columns_to_scale])\n",
    "#x_te[columns_to_scale] = scaler.fit_transform(x_te[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Evaluation Function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "import time\n",
    "\n",
    "def evaluate_classification_model(model, model_name, x_t, y_t, x_te, y_te):\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "\n",
    "    # Train model\n",
    "    training_start = time.perf_counter()\n",
    "    model.fit(x_t, y_t)\n",
    "    training_end = time.perf_counter()\n",
    "\n",
    "    best_model = model.best_estimator_ if hasattr(model, \"best_estimator_\") else model\n",
    "\n",
    "    # Predict\n",
    "    prediction_start = time.perf_counter()\n",
    "    y_pred_train = best_model.predict(x_t)\n",
    "    y_pred_test = best_model.predict(x_te)\n",
    "    prediction_end = time.perf_counter()\n",
    "\n",
    "    # If model supports predict_proba, compute AUC\n",
    "    y_proba_test = best_model.predict_proba(x_te)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "\n",
    "    # Metrics\n",
    "    train_acc = accuracy_score(y_t, y_pred_train)\n",
    "    test_acc = accuracy_score(y_te, y_pred_test)\n",
    "\n",
    "    train_f1 = f1_score(y_t, y_pred_train)\n",
    "    test_f1 = f1_score(y_te, y_pred_test)\n",
    "\n",
    "    test_auc = roc_auc_score(y_te, y_proba_test) if y_proba_test is not None else \"N/A\"\n",
    "\n",
    "    train_time = training_end - training_start\n",
    "    prediction_time = prediction_end - prediction_start\n",
    "\n",
    "    # Output\n",
    "    print(\"\\nBest Parameters:\", model.best_params_ if hasattr(model, \"best_params_\") else \"Default\")\n",
    "\n",
    "    print(\"\\nTraining Set:\")\n",
    "    print(f\"  - Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  - F1 Score: {train_f1:.4f}\")\n",
    "    print(f\"  - Training Time: {train_time:.4f} seconds\")\n",
    "\n",
    "    print(\"\\nTesting Set:\")\n",
    "    print(f\"  - Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  - F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"  - ROC AUC: {test_auc}\")\n",
    "    print(f\"  - Prediction Time: {prediction_time:.5f} seconds\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_te, y_pred_test))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_te, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SVM Classifier =====\n",
      "\n",
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Training Set:\n",
      "  - Accuracy: 0.8367\n",
      "  - F1 Score: 0.9111\n",
      "  - Training Time: 5.1720 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - Accuracy: 0.8380\n",
      "  - F1 Score: 0.9119\n",
      "  - ROC AUC: 0.5377883850437549\n",
      "  - Prediction Time: 0.02112 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        81\n",
      "           1       0.84      1.00      0.91       419\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.42      0.50      0.46       500\n",
      "weighted avg       0.70      0.84      0.76       500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0  81]\n",
      " [  0 419]]\n",
      "\n",
      "===== KNN Classifier =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS TUF\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ASUS TUF\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ASUS TUF\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "Training Set:\n",
      "  - Accuracy: 0.8433\n",
      "  - F1 Score: 0.9140\n",
      "  - Training Time: 0.3224 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - Accuracy: 0.8280\n",
      "  - F1 Score: 0.9059\n",
      "  - ROC AUC: 0.3983617666990778\n",
      "  - Prediction Time: 0.28627 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        81\n",
      "           1       0.84      0.99      0.91       419\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.42      0.49      0.45       500\n",
      "weighted avg       0.70      0.83      0.76       500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0  81]\n",
      " [  5 414]]\n",
      "\n",
      "===== Decision Tree Classifier =====\n",
      "\n",
      "Best Parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\n",
      "Training Set:\n",
      "  - Accuracy: 0.8553\n",
      "  - F1 Score: 0.9204\n",
      "  - Training Time: 0.1565 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - Accuracy: 0.8200\n",
      "  - F1 Score: 0.9007\n",
      "  - ROC AUC: 0.4911606116856713\n",
      "  - Prediction Time: 0.00188 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.02      0.04        81\n",
      "           1       0.84      0.97      0.90       419\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.50      0.50      0.47       500\n",
      "weighted avg       0.73      0.82      0.76       500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  2  79]\n",
      " [ 11 408]]\n",
      "\n",
      "===== Random Forest Classifier =====\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "\n",
      "Training Set:\n",
      "  - Accuracy: 0.9600\n",
      "  - F1 Score: 0.9767\n",
      "  - Training Time: 1.6529 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - Accuracy: 0.8380\n",
      "  - F1 Score: 0.9119\n",
      "  - ROC AUC: 0.4878900380093698\n",
      "  - Prediction Time: 0.01052 seconds\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        81\n",
      "           1       0.84      1.00      0.91       419\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.42      0.50      0.46       500\n",
      "weighted avg       0.70      0.84      0.76       500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0  81]\n",
      " [  0 419]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS TUF\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ASUS TUF\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ASUS TUF\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SVM Classifier\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "svm_clf = GridSearchCV(SVC(probability=True), svm_params, cv=3, scoring='f1', n_jobs=-1)\n",
    "evaluate_classification_model(svm_clf, \"SVM Classifier\", x_t, y_t, x_te, y_te)\n",
    "\n",
    "# KNN Classifier\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # Manhattan or Euclidean\n",
    "}\n",
    "knn_clf = GridSearchCV(KNeighborsClassifier(), knn_params, cv=3, scoring='f1', n_jobs=-1)\n",
    "evaluate_classification_model(knn_clf, \"KNN Classifier\", x_t, y_t, x_te, y_te)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "tree_params = {\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "tree_clf = GridSearchCV(DecisionTreeClassifier(random_state=42), tree_params, cv=3, scoring='f1', n_jobs=-1)\n",
    "evaluate_classification_model(tree_clf, \"Decision Tree Classifier\", x_t, y_t, x_te, y_te)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "rf_clf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=3, scoring='f1', n_jobs=-1)\n",
    "evaluate_classification_model(rf_clf, \"Random Forest Classifier\", x_t, y_t, x_te, y_te)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
